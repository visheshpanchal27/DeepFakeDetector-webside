import cv2
import numpy as np
import os

try:
    import pytesseract
    # Auto-detect Tesseract path (Windows)
    tesseract_paths = [
        r"C:\Program Files\Tesseract-OCR\tesseract.exe",
        r"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe",
    ]
    for path in tesseract_paths:
        if os.path.exists(path):
            pytesseract.pytesseract.tesseract_cmd = path
            break
    OCR_AVAILABLE = True
except:
    OCR_AVAILABLE = False


class AdvancedWatermarkDetector:
    """Advanced watermark detection with OCR and template matching"""
    
    # Enhanced AI watermark keywords - ULTRA COMPREHENSIVE
    AI_KEYWORDS = {
        'gemini': [
            'gemini', 'google ai', 'bard', 'google bard', 'g ai', 'google gemini',
            'made with gemini', 'created by gemini', 'gemini ai', 'google assistant'
        ],
        'chatgpt': [
            'chatgpt', 'chat gpt', 'openai', 'gpt', 'open ai', 'chatbot gpt',
            'made with chatgpt', 'created by chatgpt', 'gpt-4', 'gpt-3'
        ],
        'dalle': [
            'dall-e', 'dalle', 'dall e', 'dallÂ·e', 'dall e 2', 'dall e 3',
            'made with dall-e', 'created by dall-e', 'openai dalle'
        ],
        'midjourney': [
            'midjourney', 'mid journey', 'mj', 'midjourney ai', 'made with midjourney',
            'created by midjourney', 'midjourney bot'
        ],
        'stable_diffusion': [
            'stable diffusion', 'stability ai', 'sd', 'stablediffusion',
            'made with stable diffusion', 'created by stable diffusion'
        ],
        'adobe_firefly': [
            'adobe firefly', 'firefly', 'adobe ai', 'firefly ai',
            'made with firefly', 'created by adobe firefly'
        ],
        'bing': [
            'bing image creator', 'bing ai', 'microsoft bing', 'bing create',
            'made with bing', 'created by bing'
        ],
        'leonardo': [
            'leonardo.ai', 'leonardo ai', 'leonardo', 'made with leonardo',
            'created by leonardo'
        ],
        'ai_generic': [
            'ai generated', 'ai-generated', 'generated by ai', 'created with ai',
            'artificial intelligence', 'machine generated', 'ai created',
            'synthetic', 'computer generated', 'algorithmically generated',
            'neural network', 'deep learning', 'ai art', 'ai image',
            'generated image', 'synthetic media', 'fake', 'deepfake'
        ]
    }
    
    @staticmethod
    def detect_text_watermark(image):
        """Detect text-based watermarks using OCR - ENHANCED FOR GEMINI"""
        if not OCR_AVAILABLE:
            return None, 0.0, None
        
        # Verify pytesseract is configured
        try:
            import pytesseract
            # Test if tesseract is accessible
            pytesseract.get_tesseract_version()
        except:
            return None, 0.0, None
        
        try:
            # Enhanced preprocessing for better OCR
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # Multiple enhancement methods for watermark detection
            methods = [
                gray,  # Original
                cv2.GaussianBlur(gray, (3, 3), 0),  # Blur to reduce noise
                cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1],  # Otsu
                cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2),  # Adaptive
                cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)[1],  # High threshold for light text
                cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY_INV)[1],  # Inverted for dark text
            ]
            
            # Enhanced OCR configurations
            ocr_configs = [
                '--psm 11',  # Sparse text
                '--psm 8',   # Single word
                '--psm 7',   # Single text line
                '--psm 6',   # Single uniform block
                '--psm 13'   # Raw line
            ]
            
            all_text = ""
            for method in methods:
                for config in ocr_configs:
                    try:
                        text = pytesseract.image_to_string(method, config=config).lower()
                        all_text += " " + text
                    except:
                        continue
            
            # Enhanced keyword matching with partial matches
            for ai_name, keywords in AdvancedWatermarkDetector.AI_KEYWORDS.items():
                for keyword in keywords:
                    # Exact match
                    if keyword in all_text:
                        return ai_name, 1.0, keyword
                    
                    # Partial match for fragmented text
                    keyword_parts = keyword.split()
                    if len(keyword_parts) > 1:
                        parts_found = sum(1 for part in keyword_parts if part in all_text)
                        if parts_found >= len(keyword_parts) * 0.7:  # 70% of parts found
                            return ai_name, 0.8, f"partial: {keyword}"
            
            # Check for common AI indicators
            ai_indicators = ['ai', 'generated', 'artificial', 'created', 'made']
            indicator_count = sum(1 for indicator in ai_indicators if indicator in all_text)
            if indicator_count >= 2:
                return 'ai_generic', 0.6, f"ai_indicators: {indicator_count}"
            
            return None, 0.0, None
        except Exception as e:
            return None, 0.0, None
    
    @staticmethod
    def detect_corner_regions(image):
        """Detect suspicious regions in corners - ULTRA SENSITIVE FOR GEMINI"""
        h, w = image.shape[:2]
        corner_size = min(h, w) // 6  # Even larger corner region
        
        corners = {
            'top_left': image[0:corner_size, 0:corner_size],
            'top_right': image[0:corner_size, w-corner_size:w],
            'bottom_left': image[h-corner_size:h, 0:corner_size],
            'bottom_right': image[h-corner_size:h, w-corner_size:w]
        }
        
        watermark_corners = []
        
        for corner_name, corner in corners.items():
            gray = cv2.cvtColor(corner, cv2.COLOR_BGR2GRAY)
            
            # Method 1: Multiple brightness thresholds
            bright_scores = []
            for thresh in [150, 180, 200, 220]:  # Multiple thresholds
                _, bright = cv2.threshold(gray, thresh, 255, cv2.THRESH_BINARY)
                bright_ratio = np.sum(bright == 255) / bright.size
                if bright_ratio > 0.02:  # Very sensitive
                    bright_scores.append(bright_ratio)
            
            # Method 2: Enhanced edge detection
            edges_low = cv2.Canny(gray, 20, 80)   # Very sensitive
            edges_med = cv2.Canny(gray, 50, 150)  # Medium
            edge_ratio = max(
                np.sum(edges_low > 0) / edges_low.size,
                np.sum(edges_med > 0) / edges_med.size
            )
            
            # Method 3: Detect ANY objects (very wide range)
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            objects = sum(1 for c in contours if 20 < cv2.contourArea(c) < 8000)  # Very wide range
            
            # Method 4: Color variance (logos often have distinct colors)
            color_var = np.var(corner.reshape(-1, 3), axis=0).mean()
            
            # Method 5: Gemini-specific detection (blue/purple gradients)
            hsv = cv2.cvtColor(corner, cv2.COLOR_BGR2HSV)
            blue_purple_mask = cv2.inRange(hsv, (100, 50, 50), (140, 255, 255))  # Blue-purple range
            gemini_ratio = np.sum(blue_purple_mask > 0) / blue_purple_mask.size
            
            # Method 6: Text pattern detection (multiple approaches)
            text_patterns = 0
            for thresh in [100, 150, 200]:
                _, text_binary = cv2.threshold(gray, thresh, 255, cv2.THRESH_BINARY)
                text_contours, _ = cv2.findContours(text_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                text_like = sum(1 for c in text_contours if 15 < cv2.contourArea(c) < 2000)
                text_patterns = max(text_patterns, text_like)
            
            # Ultra-sensitive scoring
            score = 0
            if bright_scores:  # Any bright regions found
                score += min(0.3, max(bright_scores) * 6)  # Up to 0.3 points
            if edge_ratio > 0.02:  # Has edges (very sensitive)
                score += min(0.25, edge_ratio * 10)
            if objects > 0:  # Has any objects
                score += min(0.2, objects * 0.05)
            if color_var > 100:  # Color variation (logos)
                score += min(0.15, color_var / 1000)
            if gemini_ratio > 0.01:  # Gemini colors detected
                score += min(0.3, gemini_ratio * 20)  # High weight for Gemini
            if text_patterns > 1:  # Text-like patterns
                score += min(0.2, text_patterns * 0.05)
            
            # Special boost for bottom-right (common Gemini position)
            if corner_name == 'bottom_right' and score > 0.2:
                score += 0.1
            
            if score > 0.8:  # Much higher threshold to reduce false positives
                watermark_corners.append((corner_name, min(score, 1.0)))
        
        return watermark_corners
    
    @staticmethod
    def detect_repeating_patterns(image):
        """Detect repeating watermark patterns across image"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Divide image into grid
        h, w = gray.shape
        grid_h, grid_w = h // 4, w // 4
        
        patches = []
        for i in range(4):
            for j in range(4):
                patch = gray[i*grid_h:(i+1)*grid_h, j*grid_w:(j+1)*grid_w]
                patches.append(patch)
        
        # Check if patches are too similar (repeating watermark)
        similarities = []
        for i in range(len(patches)):
            for j in range(i+1, len(patches)):
                corr = np.corrcoef(patches[i].flatten(), patches[j].flatten())[0, 1]
                if not np.isnan(corr):
                    similarities.append(corr)
        
        if similarities:
            avg_similarity = np.mean(similarities)
            # If patches are very similar, might be repeating watermark
            if avg_similarity > 0.9:
                return True, avg_similarity
        
        return False, 0.0
    
    @staticmethod
    def detect_semi_transparent_overlay(image):
        """Detect semi-transparent overlays - ULTRA SENSITIVE"""
        # Multiple color space analysis
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        
        # Method 1: Saturation analysis (enhanced)
        saturation = hsv[:, :, 1]
        low_sat_masks = []
        for thresh in [60, 80, 100, 120]:  # Multiple thresholds
            mask = saturation < thresh
            ratio = np.sum(mask) / mask.size
            if ratio > 0.1:  # More sensitive
                low_sat_masks.append((mask, ratio))
        
        # Method 2: Lightness analysis (LAB space)
        lightness = lab[:, :, 0]
        high_light_mask = lightness > 200  # Very bright regions
        light_ratio = np.sum(high_light_mask) / high_light_mask.size
        
        # Method 3: Alpha-like detection (transparency simulation)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Multiple edge detection approaches
        edges_ultra = cv2.Canny(gray, 10, 50)   # Ultra sensitive
        edges_low = cv2.Canny(gray, 30, 100)    # Low sensitivity
        edges_med = cv2.Canny(gray, 50, 150)    # Medium sensitivity
        
        overlay_scores = []
        
        # Analyze each saturation mask
        for mask, ratio in low_sat_masks:
            for edges in [edges_ultra, edges_low, edges_med]:
                overlay_edges = edges * mask.astype(np.uint8)
                edge_ratio = np.sum(overlay_edges > 0) / overlay_edges.size
                if edge_ratio > 0.005:  # Very sensitive
                    overlay_scores.append(edge_ratio * 15)
        
        # Analyze lightness overlay
        for edges in [edges_ultra, edges_low, edges_med]:
            light_overlay = edges * high_light_mask.astype(np.uint8)
            light_edge_ratio = np.sum(light_overlay > 0) / light_overlay.size
            if light_edge_ratio > 0.005:
                overlay_scores.append(light_edge_ratio * 12)
        
        # Method 4: Color uniformity (watermarks often have uniform colors)
        h, w = image.shape[:2]
        corner_size = min(h, w) // 8
        corners = [
            image[0:corner_size, 0:corner_size],
            image[0:corner_size, w-corner_size:w],
            image[h-corner_size:h, 0:corner_size],
            image[h-corner_size:h, w-corner_size:w]
        ]
        
        for corner in corners:
            color_std = np.std(corner.reshape(-1, 3), axis=0).mean()
            if color_std < 15:  # Very uniform color (potential watermark)
                overlay_scores.append(0.3)
        
        # Determine if overlay exists
        if overlay_scores:
            max_score = max(overlay_scores)
            avg_score = sum(overlay_scores) / len(overlay_scores)
            
            # Ultra-sensitive detection
            if max_score > 0.05 or (len(overlay_scores) >= 3 and avg_score > 0.02):
                return True, min(max_score, 0.95)
        
        # Fallback: any significant low saturation or high lightness
        if low_sat_masks and max(ratio for _, ratio in low_sat_masks) > 0.2:
            return True, min(max(ratio for _, ratio in low_sat_masks) * 2, 0.8)
        
        if light_ratio > 0.15:
            return True, min(light_ratio * 3, 0.8)
        
        return False, 0.0
    
    @staticmethod
    def analyze(image):
        """Complete advanced watermark analysis - ULTRA SENSITIVE"""
        results = {
            'has_watermark': False,
            'ai_generator': None,
            'watermark_type': None,
            'confidence': 0.0,
            'details': {},
            'watermark_score': 0.0  # New field for integration
        }
        
        detection_scores = []
        
        # 1. Enhanced text-based detection (OCR) - more conservative
        ai_name, text_conf, keyword = AdvancedWatermarkDetector.detect_text_watermark(image)
        if text_conf > 0.8:  # Higher threshold for text detection
            results['has_watermark'] = True
            results['ai_generator'] = ai_name
            results['watermark_type'] = 'text'
            results['confidence'] = text_conf
            results['details']['keyword_found'] = keyword
            results['watermark_score'] = text_conf * 100
            return results
        detection_scores.append(text_conf)
        
        # 2. Conservative corner region detection
        corner_marks = AdvancedWatermarkDetector.detect_corner_regions(image)
        corner_score = 0
        if corner_marks:
            corner_score = max(score for _, score in corner_marks)
            # Stricter threshold to reduce false positives
            if corner_score > 0.6 and len(corner_marks) >= 2:  # Higher threshold + multiple corners
                results['has_watermark'] = True
                results['watermark_type'] = 'logo'
                results['confidence'] = corner_score
                results['details']['corners'] = corner_marks
                
                # Enhanced AI generator identification
                corner_names = [c[0] for c in corner_marks]
                if 'bottom_right' in corner_names:
                    results['ai_generator'] = 'gemini'  # Gemini signature
                elif 'top_right' in corner_names:
                    results['ai_generator'] = 'chatgpt'  # ChatGPT/DALL-E
                else:
                    results['ai_generator'] = 'ai_generic'
                
                results['watermark_score'] = corner_score * 100
                return results
        detection_scores.append(corner_score)
        
        # 3. Repeating pattern detection
        has_pattern, pattern_score = AdvancedWatermarkDetector.detect_repeating_patterns(image)
        if has_pattern and pattern_score > 0.85:  # Lower threshold
            results['has_watermark'] = True
            results['watermark_type'] = 'repeating'
            results['confidence'] = pattern_score
            results['details']['pattern_similarity'] = pattern_score
            results['ai_generator'] = 'ai_generic'
            results['watermark_score'] = pattern_score * 100
            return results
        detection_scores.append(pattern_score if has_pattern else 0)
        
        # 4. Conservative overlay detection
        has_overlay, overlay_score = AdvancedWatermarkDetector.detect_semi_transparent_overlay(image)
        if has_overlay and overlay_score > 0.3:  # Much higher threshold
            results['has_watermark'] = True
            results['watermark_type'] = 'overlay'
            results['confidence'] = min(overlay_score * 2, 0.8)  # Lower scaling
            results['details']['overlay_score'] = overlay_score
            results['ai_generator'] = 'ai_generic'
            results['watermark_score'] = min(overlay_score * 200, 80)
            return results
        detection_scores.append(overlay_score if has_overlay else 0)
        
        # 5. Aggregate weak signals (more conservative)
        max_score = max(detection_scores) if detection_scores else 0
        avg_score = sum(detection_scores) / len(detection_scores) if detection_scores else 0
        
        # Only flag if we have STRONG multiple signals (reduce false positives)
        strong_signals = sum(1 for score in detection_scores if score > 0.3)
        weak_signals = sum(1 for score in detection_scores if score > 0.1)
        
        if strong_signals >= 2 or (weak_signals >= 3 and avg_score > 0.25):
            results['has_watermark'] = True
            results['watermark_type'] = 'weak_signals'
            results['confidence'] = min(avg_score * 2.5, 0.7)  # Lower confidence
            results['ai_generator'] = 'ai_generic'
            results['watermark_score'] = min(avg_score * 250, 70)  # Lower score
            results['details']['weak_signals'] = weak_signals
            results['details']['strong_signals'] = strong_signals
            results['details']['detection_scores'] = detection_scores
            return results
        
        # Store scores for potential use by main detector
        results['watermark_score'] = max_score * 80  # Reduced impact
        results['details']['all_scores'] = detection_scores
        
        return results
